from PIL import Image
import numpy as np
from scipy.stats import skew, kurtosis
from collections.abc import Callable, Iterable
import math

def shot_similarity(shot_1: Iterable[Image.Image], shot_2: Iterable[Image.Image], feature_weights: tuple[float, ...]) -> float:
    # sum of frame matches between shots,
    # divided by the number of frames in the shorter of the shots
    assert sum(feature_weights) > 0.999 and sum(feature_weights) < 1.001

    shot_1_frame_feature_values: list[tuple[float, ...]] = [frame_feature_vector(frame) for frame in shot_1]
    shot_2_frame_feature_values: list[tuple[float, ...]] = [frame_feature_vector(frame) for frame in shot_2]

    min_of_shot_lengths: int = min(len(shot_1_frame_feature_values), len(shot_2_frame_feature_values))

    shot_feature_similarities: list[float] = list()
    for feature_index in range(len(shot_1_frame_feature_values[0])):
        lcs: int = longest_common_subsequence(
            [frame_features[feature_index] for frame_features in shot_1_frame_feature_values],
            [frame_features[feature_index] for frame_features in shot_2_frame_feature_values]
        )
        shot_feature_similarities.append(lcs/min_of_shot_lengths)

    assert len(feature_weights) == len(shot_feature_similarities)

    shot_similarity: float = sum(shot_feature_similarities[i]*feature_weights[i] for i in range(len(feature_weights)))

    return shot_similarity

def frame_feature_vector(frame: Image.Image) -> tuple[float, ...]:
    ffcm: tuple[float, float, float] = frame_first_colour_moment(frame)
    fscm: tuple[float, float, float] = frame_second_colour_moment(frame)
    ffd: tuple[float, float, float] = frame_fractal_dimension(frame)
    feature_vector: tuple[float, ...] = (
        ffcm[0],
        ffcm[1],
        ffcm[2],
        fscm[0],
        fscm[1],
        fscm[2],
        ffd[0],
        ffd[1],
        ffd[2]
    )
    return feature_vector

def longest_common_subsequence(shot_1_frame_feature_values: list[float], shot_2_frame_feature_values: list[float]) -> int:
    "Each shot is a list of a float-valued feature for each frame in the shot"
    m: int = len(shot_1_frame_feature_values)
    n: int = len(shot_2_frame_feature_values)
    c = np.ndarray((m, n), float)
    for i in range(m):
        c[i, 0] = 0
    for j in range(n):
        c[0, j] = 0
    for i in range(m):
        for j in range(n):
            if shot_1_frame_feature_values[i] == shot_2_frame_feature_values[j]:
                c[i, j] = c[i-1, j-1] + 1
            else:
                c[i, j] = max(c[i, j-1], c[i-1, j])

    return c[m, n]

def frame_first_colour_moment(frame: Image.Image) -> tuple[float, float, float]:
    "Mean / average colour of the frame"
    return frame_colour_moment(frame, np.mean)

def frame_second_colour_moment(frame: Image.Image) -> tuple[float, float, float]:
    "Standard deviation / the colour variance of the frame"
    return frame_colour_moment(frame, np.std)

def frame_third_colour_moment(frame: Image.Image) -> tuple[float, float, float]:
    "Skewness / how asymmetric the colour distribution is in the frame"
    return frame_colour_moment(frame, skew)

def frame_fourth_colour_moment(frame: Image.Image) -> tuple[float, float, float]:
    "Kurtosis / how extreme the tails are compared to normal distribution for the frame"
    return frame_colour_moment(frame, kurtosis)

def frame_colour_moment(frame: Image.Image, fun: Callable) -> tuple[float, float, float]:
    frame = frame.convert("RGB")
    np_image = np.array(frame)
    
    colour_moment: tuple[float, float, float] = (
        float(fun(np_image[:, :, 0])),
        float(fun(np_image[:, :, 1])),
        float(fun(np_image[:, :, 2]))
    )
    return colour_moment

def frame_fractal_dimension(frame: Image.Image) -> tuple[float, float, float]:
    "Fractal dimension index / quantifies fractal complexity of patterns in the frame"
    img = frame.convert('RGB')
    arr = np.array(img)

    r, g, b = arr[:, :, 0], arr[:, :, 1], arr[:, :, 2]

    r_binarized = r > r.mean()
    g_binarized = g > g.mean()
    b_binarized = b > b.mean()

    fractal_dimension_r: float = fractal_dimension(r_binarized)
    fractal_dimension_g: float = fractal_dimension(g_binarized)
    fractal_dimension_b: float = fractal_dimension(b_binarized)

    return (fractal_dimension_r, fractal_dimension_g, fractal_dimension_b)

def fractal_dimension(Z: np.ndarray) -> float:
    "Generated by ChatGPT"
    assert len(Z.shape) == 2
    Z = Z > 0
    p = min(Z.shape)
    n = 2**int(math.floor(math.log2(p)))

    sizes = 2**np.arange(int(math.log2(n)), 1, -1)
    counts = []

    for size in sizes:
        new_shape = (Z.shape[0] // size * size, Z.shape[1] // size * size)
        Z_crop = Z[:new_shape[0], :new_shape[1]]

        Z_reshaped = Z_crop.reshape(new_shape[0] // size, size, new_shape[1] // size, size)
        Z_blocks = Z_reshaped.any(axis=(1, 3))
        counts.append(np.sum(Z_blocks))

    coeffs = np.polyfit(np.log(sizes), np.log(counts), 1)
    return -coeffs[0]
